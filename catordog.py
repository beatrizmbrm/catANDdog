# -*- coding: utf-8 -*-
"""catORdog.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/16KO08gQE7G719gAAxhR_QNNVzZm0cBtN
"""

# Importa o modelo VGG16 pré-treinado, a função de pré-processamento e a função que traduz previsões em nomes de classes
from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input, decode_predictions

# Carrega imagens do disco e converte para array NumPy
from tensorflow.keras.preprocessing.image import load_img, img_to_array

# Permite criar modelos sequenciais (camada por camada) ou modelos funcionais (mais flexíveis)
from tensorflow.keras.models import Model, Sequential

# Biblioteca para trabalhar com arrays e matrizes numéricas
import numpy as np

# Biblioteca para exibir imagens e gráficos
import matplotlib.pyplot as plt

# Conecta o notebook ao Google Drive (para acessar imagens e salvar arquivos)
from google.colab import drive

# Permite navegar por diretórios e manipular caminhos de arquivos
import os

# Gera lotes de imagens com pré-processamento e aumento de dados (data augmentation)
from tensorflow.keras.preprocessing.image import ImageDataGenerator

# === Parâmetros Globais ===
IMG_WIDTH, IMG_HEIGHT = 224, 224
BATCH_SIZE = 32
NUM_TRAINABLE_LAYERS = 0

model = VGG16(weights='imagenet', include_top=True, input_shape=(IMG_WIDTH, IMG_HEIGHT, 3)) #carrega o modelo vgg16 cm os pesos da imageNet, include_top=false: remove as camadas densas finais, W=224, H=224, 3 rgb : define o tamanho das imagens de entrada

train_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)

train_generator = train_datagen.flow_from_directory(
    '/content/drive/MyDrive/cat&dog/training_set',  #caminho da pasta
)

target_size=(224, 224), # Redimensiona para 224x224 (formato VGG16)
batch_size=32, #lotes de 32 por vez
class_mode='binary' #classificação binaria de duas classe, se cat ou dog, logo se 1 ou 0

# caminho da pasta de imagens (dog)
caminho_dogs = '/content/drive/MyDrive/cat&dog/training_set/dogs'


# percorre todas as imagens da pasta
for filename in os.listdir(caminho_dogs): #filename= nome de cada arquivo da pasta, os.listdir= lista tds da pasta
    if filename.lower().endswith(('.jpg')): #tds arquivos jpg sejam processado
        img_path = os.path.join(caminho_dogs, filename) #junta o caminho da pasta com o nome dos arquivos

        # carrega e pre processa a imagem
        img = load_img(img_path, target_size=(224, 224)) #carrega a imagem no tamanho do VGG16(precisa isso se ja tem antes na pasta toda de treino?)
        img_array = img_to_array(img) #converte a imagem para uma matriz de pixels
        img_array = np.expand_dims(img_array, axis=0) #expande o array com uma nova dimensão pois a função model.predict() espera um grupo de imagens(com 4) e o img_to_array tem (224, 224, 3) 3 dos canais RGB
        img_array = preprocess_input(img_array) #normalização do vgg

        # predição
        preds = model.predict(img_array) #faz a previsão pela imageNet de 1000 classes predefinidas
        top_preds = decode_predictions(preds, top=10)[0] #mostra as 10 classes de mais probabilidade traduz os indices numericos nos nomes ja do pretreinamento

        # printa os resultados dos 10
        print(f"\n 10 primeiras previsões para: {filename}")
        for i, (_, label, prob) in enumerate(top_preds):
            print(f"{i+1}. {label.ljust(20)}: {prob*100:.2f}%")

        # mostra a imagem cm nome do arquivo
        plt.imshow(img)
        plt.axis("off")
        plt.title(f"{filename}")
        plt.show()

# caminho da pasta de imagens (cat)
caminho_dogs = '/content/drive/MyDrive/cat&dog/training_set/cats'


# percorre todas as imagens da pasta
for filename in os.listdir(caminho_dogs): #filename= nome de cada arquivo da pasta, os.listdir= lista tds da pasta
    if filename.lower().endswith(('.jpg')): #tds arquivos jpg sejam processado
        img_path = os.path.join(caminho_dogs, filename) #junta o caminho da pasta com o nome dos arquivos

        # carrega e pre processa a imagem
        img = load_img(img_path, target_size=(224, 224)) #carrega a imagem no tamanho do VGG16(precisa isso se ja tem antes na pasta toda de treino?)
        img_array = img_to_array(img) #converte a imagem para uma matriz de pixels
        img_array = np.expand_dims(img_array, axis=0) # expande o array com uma nova dimensão pois a função model.predict() espera um grupo de imagens(com 4) e o img_to_array tem (224, 224, 3) 3 dos canais RGB
        img_array = preprocess_input(img_array) #normalização do vgg

        # predição
        preds = model.predict(img_array) #faz a previsão pela imageNet de 1000 classes predefinidas
        top_preds = decode_predictions(preds, top=10)[0] #mostra as 10 classes de mais probabilidade traduz os indices numericos nos nomes ja do pretreinamento

        # printa os resultados dos 10
        print(f"\n 10 primeiras previsões para: {filename}")
        for i, (_, label, prob) in enumerate(top_preds):
            print(f"{i+1}. {label.ljust(20)}: {prob*100:.2f}%")

        # mostra a imagem cm nome do arquivo
        plt.imshow(img)
        plt.axis("off")
        plt.title(f"{filename}")
        plt.show()

import tensorflow as tf  # Biblioteca principal para deep learning

from tensorflow.keras.models import Sequential  # Permite criar modelos sequenciais (camada por camada)

from tensorflow.keras.layers import GlobalAveragePooling2D, Dense
# GlobalAveragePooling2D: reduz a saída 3D da CNN para um vetor 1D (resume os mapas de ativação)
# Dense: camada totalmente conectada (usada para classificação)

from tensorflow.keras.applications import VGG16
# Importa o modelo VGG16 pré-treinado (pode ser usado como extrator de características)

from tensorflow.keras.applications.vgg16 import preprocess_input
# Função que normaliza as imagens no formato que o VGG16 espera (subtrai a média dos canais RGB)

from tensorflow.keras.preprocessing.image import ImageDataGenerator
# Gera lotes de imagens com pré-processamento e aumento de dados (data augmentation)

# === directories ===
training_set = "/content/drive/MyDrive/cat&dog/training_set"
validation_set = "/content/drive/MyDrive/cat&dog/validation_set"
test_set = "/content/drive/MyDrive/cat&dog/test_set"

import os
import numpy as np
import matplotlib.pyplot as plt
from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array

# 1. Configuração do Data Augmentation
train_datagen = ImageDataGenerator(
    rotation_range=20,
    width_shift_range=0.2,
    height_shift_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True,
    fill_mode='nearest'  # Preenche pixels criados pelas transformações
)

# 2. Carrega UMA imagem de exemplo (será transformada em 10 versões)
caminho_cats = '/content/drive/MyDrive/cat&dog/training_set/cats/cat.1.jpg'
img = load_img(caminho_cats, target_size=(224, 224))
x = img_to_array(img)
x = np.expand_dims(x, axis=0)  # Adiciona dimensão do batch (1, 224, 224, 3)

# 3. Gera 10 versões aumentadas
augmented_images = [train_datagen.random_transform(x[0]) for _ in range(10)]

# 4. Plotagem em grid 2x5
plt.figure(figsize=(15, 6))
plt.suptitle('Data Augmentation - 10 Transformações da Mesma Imagem', fontsize=16)

for i, augmented_img in enumerate(augmented_images):
    plt.subplot(2, 5, i+1)
    plt.imshow(augmented_img.astype('uint8'))  # Converte para formato de imagem
    plt.axis('off')
    plt.title(f'Exemplo {i+1}')

plt.tight_layout()
plt.show()

# aprendizagem de transferencia

# Create a separate ImageDataGenerator for validation and test sets without augmentation
val_test_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)

train_generator = train_datagen.flow_from_directory(
    training_set,
    target_size=(IMG_WIDTH, IMG_HEIGHT), #dimensoes
    batch_size=BATCH_SIZE, #quantas usa por vez(32)
    class_mode="binary" #(0 ou 1)
)
validation_generator = val_test_datagen.flow_from_directory(
    validation_set,
    target_size=(IMG_WIDTH, IMG_HEIGHT),
    batch_size=BATCH_SIZE,
    class_mode="binary"
)
test_generator = val_test_datagen.flow_from_directory(
    test_set,
    target_size=(IMG_WIDTH, IMG_HEIGHT),
    batch_size=BATCH_SIZE,
    class_mode="binary",
    shuffle=False
    )

model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))

#essas sao as camadas finais que treina se o VGG estiver congelado
# == cada linha dentro da lista é uma camada da rede neural ==
totaly_model = Sequential([
model,
GlobalAveragePooling2D(), #(?) resume o quanto cada uma dessas características apareceu, com um único número para cada.
                            #Transforma uma saída 3D em um vetor simples que pode ser conectado a camadas densas.
                            #Reduz muito a quantidade de dados
Dense(64, activation='relu'), #função de ativação, apos multiplicar os pesos e soma dos vieis, cada um do 64 neuronio aplica a função ReLU na saida
Dense(1, activation='sigmoid') #usa um neoronio de ativação para classificação binaria, 0 ou 1 ex: 0.1, 0.2, 0.3... o mais proximo de 0 ou 1 eh a classe que pertence
])
totaly_model.summary() #printa o sequential com as camadas

# == Compile ==
totaly_model.compile(optimizer=tf.keras.optimizers.Adam(0.001),  #PESQUISAR MAIS SOBRE. adam é para otimizar e ajustar pesos, 0.001 taxa de aprendizado
loss='binary_crossentropy', #loss= função de perda, o quanto a previsão esta errada em relaçao ap valor real
metrics=['accuracy']) #metrica de quantas previsoes acertou

## # congela todas as camadas
for layer in model.layers:
    layer.trainable = False

## #  descongela as últimas 4 camadas se maior q 0
if NUM_TRAINABLE_LAYERS > 0:
    for layer in model.layers[-NUM_TRAINABLE_LAYERS:]: #seleciona as últimas N camadas da lista
        layer.trainable = True #torna a camada treinável
model.summary() #printa essa arquitetura abaixo

y_pred = (totaly_model.predict(test_generator) > 0.5).astype("int32")

totaly_model.fit(
    train_generator,#conjunto pro treino
    epochs=10, #o modelo passa X vezes por todo conjunto de treino
    validation_data=validation_generator #conjunto de validação que verifica se o modelo
)

loss, accuracy = totaly_model.evaluate(test_generator)
print(f"Teste acuracia: {accuracy:.4f}")